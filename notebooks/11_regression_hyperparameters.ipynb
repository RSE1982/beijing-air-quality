{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ebc7c9",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Beijing Air Quality\n",
    "## ðŸ“˜ Notebook 11 â€“ Advanced Regression & Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58899ad",
   "metadata": {},
   "source": [
    "| Field         | Description                                        |\n",
    "|:--------------|:---------------------------------------------------|\n",
    "| Author:       |\tRobert Steven Elliott                            |\n",
    "| Course:       |\tCode Institute â€“ Data Analytics with AI Bootcamp |\n",
    "| Project Type: |\tCapstone                                         |\n",
    "| Date:         |\tDecember 2025                                    |\n",
    "\n",
    "This project complies with the CC BY 4.0 licence by including proper attribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac72fff",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "1. Multi-model regression benchmarking\n",
    "    - Linear Regression\n",
    "    - Decision Tree Regressor\n",
    "    - Random Forest Regressor\n",
    "    - AdaBoost Regressor\n",
    "    - XGBoost Regressor\n",
    "2. Hyperparameter search using GridSearchCV\n",
    "3. Performance comparison (MAE, RMSE, RÂ²)\n",
    "4. Select the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b553c",
   "metadata": {},
   "source": [
    "## Citation  \n",
    "This project uses data from:\n",
    "\n",
    "Chen, Song (2017). *Beijing Multi-Site Air Quality.*  \n",
    "UCI Machine Learning Repository â€” Licensed under **CC BY 4.0**.  \n",
    "DOI: https://doi.org/10.24432/C5RK5G  \n",
    "Kaggle mirror by Manu Siddhartha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fbf77b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d08da",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f35e3d",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "(The following libraries support analysis, plotting, and data manipulation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df93568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # system-level operations\n",
    "import pandas as pd # data manipulation\n",
    "import numpy as np # numerical operations\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # statistical data visualization\n",
    "import plotly.express as px # interactive plotting\n",
    "from pathlib import Path # filesystem paths\n",
    "import json # JSON handling\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, train_test_split # model selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # model evaluation\n",
    "from sklearn.linear_model import LinearRegression # linear regression model\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree model\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor # ensemble models\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from xgboost import XGBRegressor # XGBoost model\n",
    "from pandas.api.types import CategoricalDtype # categorical data types\n",
    "import joblib # model serialization\n",
    "import warnings # warning control\n",
    "warnings.filterwarnings(action=\"ignore\") # ignore warnings for cleaner output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4e6c5",
   "metadata": {},
   "source": [
    "### Configure Visual Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02418296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use(\"seaborn-v0_8\") # set matplotlib style\n",
    "sns.set_theme() # set seaborn theme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f5f53",
   "metadata": {},
   "source": [
    "### Set Up Project Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830a81f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path : /home/robert/Projects/beijing-air-quality/data/engineered/beijing_engineered.csv\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd().parent # Assuming this script is in a subdirectory of the project root\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" # Path to the data directory\n",
    "MODELS_PATH = PROJECT_ROOT / \"models\" # Path to save models\n",
    "MODELS_PATH.mkdir(exist_ok=True) # Create models directory if it doesn't exist\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT)) # Add project root to sys.path\n",
    "\n",
    "FIGURES_PATH = PROJECT_ROOT / \"figures\" / \"modelling\" # Path to save figures\n",
    "FIGURES_PATH.mkdir(parents=True, exist_ok=True) # Create directory if it doesn't exist\n",
    "INPUT_PATH = DATA_PATH / \"engineered\" / \"beijing_engineered.csv\" # input file path\n",
    "print(\"Input path :\", INPUT_PATH) # Print input path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755fe5a",
   "metadata": {},
   "source": [
    "### include custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ebe940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.feature_engineering import apply_forecasting_features # custom feature engineering function\n",
    "from utils.load_csv import load_csv # custom data loading function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e8029",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f2965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved categorical dtypes for season & area_type.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pm25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temperature",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pressure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dew_point",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rain",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wind_direction",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "wind_speed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "station",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "area_type",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "season",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "day_of_week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour_sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_cos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_sin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_cos",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dew_point_spread",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "temp_pres_interaction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rain_binary",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "relative_humidity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1983a4d1-2558-4319-a6af-92d070451cf8",
       "rows": [
        [
         "0",
         "2013-03-01 00:00:00",
         "2013",
         "3",
         "1",
         "0",
         "4.0",
         "-0.7",
         "1023.0",
         "-18.8",
         "0.0",
         "NNW",
         "4.4",
         "0",
         "40.003388",
         "116.407613",
         "2",
         "1",
         "4",
         "0.0",
         "1.0",
         "1.0",
         "6.123233995736766e-17",
         "18.1",
         "-716.0999999999999",
         "0",
         "24.00884245457254"
        ],
        [
         "1",
         "2013-03-01 01:00:00",
         "2013",
         "3",
         "1",
         "1",
         "8.0",
         "-1.1",
         "1023.2",
         "-18.2",
         "0.0",
         "N",
         "4.7",
         "0",
         "40.003388",
         "116.407613",
         "2",
         "1",
         "4",
         "0.2588190451025207",
         "0.9659258262890684",
         "1.0",
         "6.123233995736766e-17",
         "17.099999999999998",
         "-1125.5200000000002",
         "0",
         "26.01367846905942"
        ],
        [
         "2",
         "2013-03-01 02:00:00",
         "2013",
         "3",
         "1",
         "2",
         "7.0",
         "-1.1",
         "1023.5",
         "-18.2",
         "0.0",
         "NNW",
         "5.6",
         "0",
         "40.003388",
         "116.407613",
         "2",
         "1",
         "4",
         "0.4999999999999999",
         "0.8660254037844387",
         "1.0",
         "6.123233995736766e-17",
         "17.099999999999998",
         "-1125.85",
         "0",
         "26.01367846905942"
        ],
        [
         "3",
         "2013-03-01 03:00:00",
         "2013",
         "3",
         "1",
         "3",
         "6.0",
         "-1.4",
         "1024.5",
         "-19.4",
         "0.0",
         "NW",
         "3.1",
         "0",
         "40.003388",
         "116.407613",
         "2",
         "1",
         "4",
         "0.7071067811865475",
         "0.7071067811865476",
         "1.0",
         "6.123233995736766e-17",
         "18.0",
         "-1434.3",
         "0",
         "24.00775337719314"
        ],
        [
         "4",
         "2013-03-01 04:00:00",
         "2013",
         "3",
         "1",
         "4",
         "3.0",
         "-2.0",
         "1025.2",
         "-19.5",
         "0.0",
         "N",
         "2.0",
         "0",
         "40.003388",
         "116.407613",
         "2",
         "1",
         "4",
         "0.8660254037844386",
         "0.5000000000000001",
         "1.0",
         "6.123233995736766e-17",
         "17.5",
         "-2050.4",
         "0",
         "24.876783014999248"
        ]
       ],
       "shape": {
        "columns": 26,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm25</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>dew_point_spread</th>\n",
       "      <th>temp_pres_interaction</th>\n",
       "      <th>rain_binary</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-03-01 00:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>18.1</td>\n",
       "      <td>-716.10</td>\n",
       "      <td>0</td>\n",
       "      <td>24.008842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-01 01:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-1125.52</td>\n",
       "      <td>0</td>\n",
       "      <td>26.013678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-03-01 02:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-1125.85</td>\n",
       "      <td>0</td>\n",
       "      <td>26.013678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-01 03:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1434.30</td>\n",
       "      <td>0</td>\n",
       "      <td>24.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-03-01 04:00:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>17.5</td>\n",
       "      <td>-2050.40</td>\n",
       "      <td>0</td>\n",
       "      <td>24.876783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  year  month  day  hour  pm25  temperature  pressure  \\\n",
       "0 2013-03-01 00:00:00  2013      3    1     0   4.0         -0.7    1023.0   \n",
       "1 2013-03-01 01:00:00  2013      3    1     1   8.0         -1.1    1023.2   \n",
       "2 2013-03-01 02:00:00  2013      3    1     2   7.0         -1.1    1023.5   \n",
       "3 2013-03-01 03:00:00  2013      3    1     3   6.0         -1.4    1024.5   \n",
       "4 2013-03-01 04:00:00  2013      3    1     4   3.0         -2.0    1025.2   \n",
       "\n",
       "   dew_point  rain  ... season  day_of_week  hour_sin  hour_cos  month_sin  \\\n",
       "0      -18.8   0.0  ...      1            4  0.000000  1.000000        1.0   \n",
       "1      -18.2   0.0  ...      1            4  0.258819  0.965926        1.0   \n",
       "2      -18.2   0.0  ...      1            4  0.500000  0.866025        1.0   \n",
       "3      -19.4   0.0  ...      1            4  0.707107  0.707107        1.0   \n",
       "4      -19.5   0.0  ...      1            4  0.866025  0.500000        1.0   \n",
       "\n",
       "      month_cos  dew_point_spread  temp_pres_interaction  rain_binary  \\\n",
       "0  6.123234e-17              18.1                -716.10            0   \n",
       "1  6.123234e-17              17.1               -1125.52            0   \n",
       "2  6.123234e-17              17.1               -1125.85            0   \n",
       "3  6.123234e-17              18.0               -1434.30            0   \n",
       "4  6.123234e-17              17.5               -2050.40            0   \n",
       "\n",
       "   relative_humidity  \n",
       "0          24.008842  \n",
       "1          26.013678  \n",
       "2          26.013678  \n",
       "3          24.007753  \n",
       "4          24.876783  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_csv(INPUT_PATH) # Load cleaned data\n",
    "# Freeze categories for season\n",
    "\n",
    "season_dtype = CategoricalDtype(\n",
    "    categories=sorted(df[\"season\"].unique()),\n",
    "    ordered=False\n",
    ") # define categorical dtype\n",
    "df[\"season\"] = df[\"season\"].astype(season_dtype) # convert to categorical\n",
    "df[\"season\"] = df[\"season\"].cat.codes.astype(\"int16\") # convert to integer codes\n",
    "\n",
    "# Freeze area_type category order\n",
    "area_dtype = CategoricalDtype(\n",
    "    categories=sorted(df[\"area_type\"].unique()),\n",
    "    ordered=False\n",
    ") # define categorical dtype\n",
    "df[\"area_type\"] = df[\"area_type\"].astype(area_dtype) # convert to categorical\n",
    "df[\"area_type\"] = df[\"area_type\"].cat.codes.astype(\"int16\") # convert to integer codes\n",
    "\n",
    "station_dtype = CategoricalDtype(\n",
    "    categories=sorted(df[\"station\"].unique()),\n",
    "    ordered=False\n",
    ") # define categorical dtype\n",
    "df[\"station\"] = df[\"station\"].astype(station_dtype) # convert to categorical\n",
    "df[\"station\"] = df[\"station\"].cat.codes.astype(\"int16\") # convert to integer codes\n",
    "\n",
    "# Save the frozen dtypes for Notebook 12 â€“ Forecasting\n",
    "joblib.dump(season_dtype, MODELS_PATH / \"season_dtype.joblib\")\n",
    "joblib.dump(area_dtype, MODELS_PATH / \"area_dtype.joblib\")\n",
    "joblib.dump(station_dtype, MODELS_PATH / \"station_dtype.joblib\")\n",
    "\n",
    "print(\"Saved categorical dtypes for season & area_type.\")\n",
    "\n",
    "df[\"day_of_week\"] = df[\"day_of_week\"].astype(int) # Ensure day_of_week is integer\n",
    "\n",
    "object_cols = df.select_dtypes(include=\"object\").columns # Identify object columns\n",
    "df.drop(columns=object_cols, axis=\"columns\", inplace=True) # Drop object columns\n",
    "\n",
    "df.head() # Display first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c63ee7",
   "metadata": {},
   "source": [
    "## Data Overview Analysis\n",
    "\n",
    "(Understanding structure, completeness, and variable types.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877dc92a",
   "metadata": {},
   "source": [
    "### Structure + Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7fd1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 403776 entries, 0 to 403775\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   datetime               403776 non-null  datetime64[ns]\n",
      " 1   year                   403776 non-null  int64         \n",
      " 2   month                  403776 non-null  int64         \n",
      " 3   day                    403776 non-null  int64         \n",
      " 4   hour                   403776 non-null  int64         \n",
      " 5   pm25                   403776 non-null  float64       \n",
      " 6   temperature            403776 non-null  float64       \n",
      " 7   pressure               403776 non-null  float64       \n",
      " 8   dew_point              403776 non-null  float64       \n",
      " 9   rain                   403776 non-null  float64       \n",
      " 10  wind_direction         403776 non-null  category      \n",
      " 11  wind_speed             403776 non-null  float64       \n",
      " 12  station                403776 non-null  int16         \n",
      " 13  latitude               403776 non-null  float64       \n",
      " 14  longitude              403776 non-null  float64       \n",
      " 15  area_type              403776 non-null  int16         \n",
      " 16  season                 403776 non-null  int16         \n",
      " 17  day_of_week            403776 non-null  int64         \n",
      " 18  hour_sin               403776 non-null  float64       \n",
      " 19  hour_cos               403776 non-null  float64       \n",
      " 20  month_sin              403776 non-null  float64       \n",
      " 21  month_cos              403776 non-null  float64       \n",
      " 22  dew_point_spread       403776 non-null  float64       \n",
      " 23  temp_pres_interaction  403776 non-null  float64       \n",
      " 24  rain_binary            403776 non-null  int64         \n",
      " 25  relative_humidity      403776 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](1), float64(15), int16(3), int64(6)\n",
      "memory usage: 70.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe Shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(403776, 26)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "bc09a8ee-2c1d-43cb-b3be-fa7d19972f69",
       "rows": [
        [
         "datetime",
         "0"
        ],
        [
         "year",
         "0"
        ],
        [
         "month",
         "0"
        ],
        [
         "day",
         "0"
        ],
        [
         "hour",
         "0"
        ],
        [
         "pm25",
         "0"
        ],
        [
         "temperature",
         "0"
        ],
        [
         "pressure",
         "0"
        ],
        [
         "dew_point",
         "0"
        ],
        [
         "rain",
         "0"
        ],
        [
         "wind_direction",
         "0"
        ],
        [
         "wind_speed",
         "0"
        ],
        [
         "station",
         "0"
        ],
        [
         "latitude",
         "0"
        ],
        [
         "longitude",
         "0"
        ],
        [
         "area_type",
         "0"
        ],
        [
         "season",
         "0"
        ],
        [
         "day_of_week",
         "0"
        ],
        [
         "hour_sin",
         "0"
        ],
        [
         "hour_cos",
         "0"
        ],
        [
         "month_sin",
         "0"
        ],
        [
         "month_cos",
         "0"
        ],
        [
         "dew_point_spread",
         "0"
        ],
        [
         "temp_pres_interaction",
         "0"
        ],
        [
         "rain_binary",
         "0"
        ],
        [
         "relative_humidity",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 26
       }
      },
      "text/plain": [
       "datetime                 0\n",
       "year                     0\n",
       "month                    0\n",
       "day                      0\n",
       "hour                     0\n",
       "pm25                     0\n",
       "temperature              0\n",
       "pressure                 0\n",
       "dew_point                0\n",
       "rain                     0\n",
       "wind_direction           0\n",
       "wind_speed               0\n",
       "station                  0\n",
       "latitude                 0\n",
       "longitude                0\n",
       "area_type                0\n",
       "season                   0\n",
       "day_of_week              0\n",
       "hour_sin                 0\n",
       "hour_cos                 0\n",
       "month_sin                0\n",
       "month_cos                0\n",
       "dew_point_spread         0\n",
       "temp_pres_interaction    0\n",
       "rain_binary              0\n",
       "relative_humidity        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dataframe Info:\") # Display dataframe info\n",
    "display(df.info()) # Display dataframe info\n",
    "print(\"\\nDataframe Shape:\") # Display dataframe shape\n",
    "display(df.shape) # Display dataframe shape\n",
    "print(\"\\nMissing Values:\") # Check for missing values\n",
    "display(df.isna().sum()) # Check for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b4b20b",
   "metadata": {},
   "source": [
    "## Select Modelling Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c0fa1",
   "metadata": {},
   "source": [
    "We use all engineered features, including lags and rolling means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986330e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"pm25\" # Define target variable\n",
    "\n",
    "drop_cols = [\n",
    "    \"latitude\", \"longitude\",\n",
    "    \"pm25\", \"datetime\", \n",
    "    \"wind_direction\"\n",
    "]\n",
    "\n",
    "feature_cols = [\n",
    "    col for col in df.columns \n",
    "    if col not in drop_cols\n",
    "] # Define feature columns excluding target and non-feature columns\n",
    "\n",
    "X = df[feature_cols].dropna() # Features dataframe with missing values dropped\n",
    "y = df.loc[X.index, \"pm25\"] # Target series aligned with features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e20d0e",
   "metadata": {},
   "source": [
    "## Train/Test Split (Time-Ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99795134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2013-03-01 00:00:00 to 2016-03-26 14:00:00\n",
      "Test range : 2016-03-26 14:00:00 to 2016-12-31 23:00:00\n",
      "Train shape: (323020, 35)\n",
      "Test shape: (80756, 35)\n",
      "Train shape after dropping NA: (262261, 35)\n",
      "Test shape after dropping NA: (13424, 35)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.sort_values(\"datetime\") # Sort by datetime\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=False) # Time-based train-test split\n",
    "\n",
    "print(\"Train range:\", train[\"datetime\"].min(), \"to\", train[\"datetime\"].max())\n",
    "print(\"Test range :\", test[\"datetime\"].min(), \"to\", test[\"datetime\"].max())\n",
    "\n",
    "train = apply_forecasting_features(train, add_lags=True, add_rollings=True)\n",
    "test  = apply_forecasting_features(test, add_lags=True, add_rollings=True)\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "train = train.dropna() # Drop rows with missing values in training set\n",
    "test = test.dropna()  # Drop rows with missing values in testing set\n",
    "\n",
    "print(\"Train shape after dropping NA:\", train.shape)\n",
    "print(\"Test shape after dropping NA:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e2a84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature names: 29\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"temperature\", \"dew_point\", \"pressure\", \"rain\", \"wind_speed\",\n",
    "    \"temp_pres_interaction\", \"dew_point_spread\", \"rain_binary\",\n",
    "    \"area_type\", \"hour_sin\", \"hour_cos\", \"month_sin\", \"month_cos\",\n",
    "    \"area_type\",\"season\", \"day_of_week\", \"month\", \n",
    "    \"year\", \"station\", \"relative_humidity\",\n",
    "    \"pm25_lag_1h\", \"pm25_lag_3h\", \"pm25_lag_6h\",\n",
    "    \"pm25_lag_12h\", \"pm25_lag_18h\",\n",
    "    \"pm25_roll_3h_mean\", \"pm25_roll_6h_mean\",\n",
    "    \"pm25_roll_12h_mean\", \"pm25_roll_18h_mean\"\n",
    "] # Define final feature set\n",
    "\n",
    "joblib.dump(features, MODELS_PATH / \"forecasting_feature_names.joblib\") # Save feature names\n",
    "print(\"Saved feature names:\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9153dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[\"pm25\"]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[\"pm25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc383fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_ in [X_train, X_test]:\n",
    "    cat_cols = df_.select_dtypes(include=[\"category\"]).columns\n",
    "    for col in cat_cols:\n",
    "        df_[col] = df_[col].cat.codes.astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2460e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643bb4a",
   "metadata": {},
   "source": [
    "## Define Algorithms & Hyperparameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f950815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_grids = {\n",
    "\n",
    "    # Linear Regression\n",
    "    \"LinearRegression\": {\n",
    "        \"model\": LinearRegression(), # Linear Regression model\n",
    "        \"params\": {\n",
    "            \"fit_intercept\": [True, False] # Hyperparameter grid\n",
    "        }\n",
    "    }, \n",
    "    # Decision Tree Regressor\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeRegressor(random_state=42), # Decision Tree model\n",
    "        \"params\": {\n",
    "            \"max_depth\": [5, 10, 20], # maximum depth of the tree\n",
    "            \"min_samples_split\": [2, 10, 20] # minimum number of samples required to split an internal node\n",
    "        } \n",
    "    },\n",
    "    # Random Forest Regressor\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42, n_jobs=-1), # Random Forest model\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100], # number of trees in the forest\n",
    "            \"max_depth\": [10, 20], # maximum depth of the tree\n",
    "            \"max_features\": [\"sqrt\", \"log2\"] # number of features to consider at each split\n",
    "        }\n",
    "    },\n",
    "    # AdaBoost Regressor\n",
    "    \"AdaBoost\": {\n",
    "        \"model\": AdaBoostRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100], # number of weak learners\n",
    "            \"learning_rate\": [0.5, 1.0] # learning rate shrinks the contribution of each weak learner\n",
    "        }\n",
    "    },\n",
    "    # XGBoost Regressor\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBRegressor(\n",
    "            objective=\"reg:squarederror\", # objective function for regression\n",
    "            eval_metric=\"rmse\", # evaluation metric\n",
    "            random_state=42, # random seed for reproducibility\n",
    "            n_estimators=200 # number of boosting rounds\n",
    "        ),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [4, 6, 8], # maximum depth of a tree\n",
    "            \"learning_rate\": [0.05, 0.1, 0.2], # step size shrinkage\n",
    "            \"subsample\": [0.8, 1.0] # fraction of samples used for fitting the individual base learners\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6f4ab",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running GridSearch for: LinearRegression\n",
      "\n",
      "Running GridSearch for: DecisionTree\n",
      "\n",
      "Running GridSearch for: RandomForest\n",
      "\n",
      "Running GridSearch for: AdaBoost\n",
      "\n",
      "Running GridSearch for: XGBoost\n"
     ]
    }
   ],
   "source": [
    "results = [] # to store results\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5) # time series cross-validation\n",
    "\n",
    "# Iterate over models and their hyperparameter grids\n",
    "\n",
    "for name, cfg in models_and_grids.items(): \n",
    "    print(f\"\\nRunning GridSearch for: {name}\")  # Log current model\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=cfg[\"model\"], # model to tune\n",
    "        param_grid=cfg[\"params\"], # hyperparameter grid\n",
    "        scoring=\"neg_mean_squared_error\", # evaluation metric\n",
    "        refit=True, # refit best model\n",
    "        error_score=\"raise\", # raise error on failure\n",
    "        cv=tscv, # cross-validation strategy\n",
    "        n_jobs=-1, # use all available cores\n",
    "        verbose=0 # verbosity level\n",
    "    ) # Initialize GridSearchCV\n",
    "    \n",
    "    grid.fit(X_train.values, y_train.values) # Fit grid search\n",
    "    best_model = grid.best_estimator_ # Get best model\n",
    "    preds = best_model.predict(X_test.values) # Make predictions on test set\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": grid.best_params_, # Store best hyperparameters\n",
    "        \"MAE\": mean_absolute_error(y_test, preds), # Mean Absolute Error\n",
    "        \"RMSE\": mean_squared_error(y_test, preds, squared=False), # Root Mean Squared Error\n",
    "        \"R2\": r2_score(y_test, preds), # R-squared\n",
    "        \"Estimator\": best_model # Best estimator\n",
    "    }) # Store results\n",
    "\n",
    "results_df = pd.DataFrame(results) # Convert results to DataFrame\n",
    "results_df  # Display results DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61b0ec",
   "metadata": {},
   "source": [
    "## Model Performance Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681793e",
   "metadata": {},
   "source": [
    "Understanding the performance of each model visually helps compare algorithms beyond raw metrics.\n",
    "\n",
    "The following plots summarise model accuracy, generalisation behaviour, and error patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6195b91",
   "metadata": {},
   "source": [
    "### RMSE, MAE, and RÂ² Comparison Across All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cc69c",
   "metadata": {},
   "source": [
    "#### Purpose\n",
    "\n",
    "This chart highlights the strengths and weaknesses of each model across the three key metrics.\n",
    "It helps identify which algorithms consistently perform well â€” not just the final winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b47ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison plot\n",
    "metrics = [\"MAE\", \"RMSE\", \"R2\"] # metrics to plot\n",
    "\n",
    "plt.figure(figsize=(12,6)) # Set figure size\n",
    "# Plot each metric\n",
    "for metric in metrics:\n",
    "    plt.plot(results_df[\"Model\"], \n",
    "             results_df[metric], #\n",
    "             marker=\"o\", \n",
    "             label=metric) # Plot each metric\n",
    "\n",
    "plt.title(\"Model Comparison: MAE, RMSE, and RÂ²\") # Title\n",
    "plt.xlabel(\"Model\") # X-axis label\n",
    "plt.ylabel(\"Metric Value\") # Y-axis label\n",
    "plt.xticks(rotation=45) # Rotate x-axis labels for better readability\n",
    "plt.legend() # Show legend\n",
    "plt.grid(alpha=0.3) # Add grid with transparency\n",
    "plt.tight_layout() # Adjust layout to prevent clipping\n",
    "plt.savefig(FIGURES_PATH / \"model_performance_comparison.png\") # Save the figure\n",
    "plt.show() # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9d897",
   "metadata": {},
   "source": [
    "### RMSE Bar Chart (Ranked Models)\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "RMSE is often the most important metric in forecasting tasks because it penalises large errors.\n",
    "This makes it the best indicator of real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3510a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6)) # Set figure size\n",
    "sns.barplot(data=results_df.sort_values(\"RMSE\"), \n",
    "            x=\"Model\", \n",
    "            y=\"RMSE\") # Bar plot of RMSE by model\n",
    "plt.title(\"RMSE by Model (Lower is Better)\") # Title\n",
    "plt.ylabel(\"RMSE\") # Y-axis label\n",
    "plt.xticks(rotation=45) # Rotate x-axis labels for better readability\n",
    "plt.tight_layout() # Adjust layout to prevent clipping\n",
    "plt.savefig(FIGURES_PATH / \"rmse_ranked_models.png\") # Save the figure\n",
    "plt.show() # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad512c9",
   "metadata": {},
   "source": [
    "### Predicted vs Actual Plot (Best Model)\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "Shows how closely the model's predictions match real PM2.5 values.\n",
    "\n",
    "Strong alignment with the diagonal means good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds = best_model.predict(X_test) # Predictions from the best model\n",
    "\n",
    "plt.figure(figsize=(10,6)) # Predicted vs Actual plot for the best model\n",
    "plt.scatter(y_test[:500], best_preds[:500], alpha=0.5) # Plot first 500 points for clarity\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\") # 45-degree line\n",
    "plt.xlabel(\"Actual PM2.5\") # X Labels\n",
    "plt.ylabel(\"Predicted PM2.5\") # Y Labels\n",
    "plt.title(\"Predicted vs Actual â€“ Best Model\") # Title\n",
    "plt.grid(alpha=0.3) # Grid with transparency\n",
    "plt.tight_layout() # Adjust layout\n",
    "plt.savefig(FIGURES_PATH / \"predicted_vs_actual_best_model.png\") # Save figure\n",
    "plt.show() # Display plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d74894",
   "metadata": {},
   "source": [
    "### Residual Distribution Plot\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "Residuals (actual - predicted) reveal patterns such as model bias or non-linearity.\n",
    "\n",
    "Well-performing models produce residuals centred around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - best_preds # Calculate residuals\n",
    "\n",
    "plt.figure(figsize=(10,6)) # Residual distribution plot for the best model\n",
    "sns.histplot(residuals, kde=True, bins=40) # Histogram of residuals\n",
    "plt.title(\"Residual Distribution â€“ Best Model\") # Title\n",
    "plt.xlabel(\"Residual (Actual â€“ Predicted)\") # X Label\n",
    "plt.tight_layout() # Adjust layout\n",
    "plt.savefig(FIGURES_PATH / \"residual_distribution.png\") # Save figure\n",
    "plt.show() # Display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e56cb",
   "metadata": {},
   "source": [
    "### Residuals vs Predicted Values\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "Reveals heteroscedasticity (variance changing over time) and systematic errors.\n",
    "\n",
    "Points should be evenly scattered around zero â€” funnels or curves indicate issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad40668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6)) # Residuals vs Predicted Values plot for the best model\n",
    "plt.scatter(best_preds[:500], \n",
    "            residuals[:500], \n",
    "            alpha=0.4) # Plot first 500 residuals for clarity\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\") # Horizontal line at y=0\n",
    "plt.xlabel(\"Predicted PM2.5\") # Labels\n",
    "plt.ylabel(\"Residual\") # Labels\n",
    "plt.title(\"Residuals vs Predicted Values â€“ Best Model\") # Title\n",
    "plt.grid(alpha=0.3) # Grid with transparency\n",
    "plt.tight_layout() # Adjust layout\n",
    "plt.savefig(FIGURES_PATH / \"residuals_vs_predicted.png\") # Save figure\n",
    "plt.show() # Display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8c3fb",
   "metadata": {},
   "source": [
    "### Feature Importance (for Tree-Based Best Models)\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "Shows which features contributed most to the prediction â€” essential for explainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot for the best model\n",
    "if hasattr(best_model, \"feature_importances_\"):\n",
    "    importances = pd.Series(best_model.feature_importances_, index=X_train.columns) # Feature importances\n",
    "    plt.figure(figsize=(10,8)) # Set figure size\n",
    "    importances.sort_values().tail(15).plot(kind=\"barh\") # Horizontal bar plot of top 15 feature importances\n",
    "    plt.title(\"Top 15 Feature Importances â€“ Best Model\") # Title\n",
    "    plt.xlabel(\"Importance\") # X Label\n",
    "    plt.tight_layout() # Adjust layout\n",
    "    plt.savefig(FIGURES_PATH / \"feature_importance_best_model.png\") # Save figure\n",
    "    plt.show() # Display plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0f395",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- The comparison chart highlights clear performance differences between the tested models.\n",
    "- The best-performing model shows the lowest RMSE, indicating strong forecasting accuracy.\n",
    "- The predicted vs actual plot confirms that the model closely tracks true PM2.5 behaviour, with only minor deviations during high-pollution episodes.\n",
    "- Residual plots suggest no major bias or systematic error patterns.\n",
    "- Feature importance reveals which engineered features (lags, rolling means, or meteorology) drive predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2709239",
   "metadata": {},
   "source": [
    "\n",
    "### Justification\n",
    "\n",
    "These visualisations provide quantitative and qualitative validation of model behaviour.\n",
    "- They confirm:\n",
    "    - Good generalisation to unseen data\n",
    "    - Reliable predictive accuracy\n",
    "    - Interpretability of model decisions\n",
    "    - Hyperparameter search selecting a robust estimator\n",
    "This evidence supports choosing the final best model for forecasting in Notebook 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519021a",
   "metadata": {},
   "source": [
    "## Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e138c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.sort_values(\"RMSE\").iloc[0] # Get best model row\n",
    "best_model = best_row[\"Estimator\"] # Best estimator\n",
    "\n",
    "print(\"Best model:\", best_row[\"Model\"]) # Print best model details\n",
    "print(\"MAE:\", best_row[\"MAE\"]) # Print best model details\n",
    "print(\"RMSE:\", best_row[\"RMSE\"]) # Print best model details\n",
    "print(\"R2:\", best_row[\"R2\"]) # Print best model details\n",
    "print(\"Params:\", best_row[\"Best Params\"]) # Print best model details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5381b",
   "metadata": {},
   "source": [
    "## Check for Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing chosen model for leakage...\\n\") # Leakage test procedure\n",
    "\n",
    "# 1. Normal performance (expected good R2) \n",
    "normal_preds = best_model.predict(X_test) # Predict on real test set\n",
    "normal_r2 = r2_score(y_test, normal_preds) # Calculate R2\n",
    "print(\"Normal R2:\", normal_r2) # Print normal R2\n",
    "\n",
    "# 2. Shuffle the TARGET for training\n",
    "y_train_shuffled = y_train.sample(frac=1.0, random_state=42) # Shuffle target variable\n",
    "\n",
    "# Refit the same model type with shuffled target\n",
    "model_shuffled = best_model.__class__(**best_model.get_params()) # Initialize new model instance\n",
    "model_shuffled.fit(X_train, y_train_shuffled)\n",
    "\n",
    "# Predict on real test set\n",
    "shuffled_preds = model_shuffled.predict(X_test) # Predictions with shuffled target model\n",
    "shuffled_r2 = r2_score(y_test, shuffled_preds) # Calculate R2 for shuffled model\n",
    "print(\"Shuffled R2:\", shuffled_r2) # Print shuffled R2\n",
    "\n",
    "# Optional: summarise\n",
    "if shuffled_r2 < 0: # Negative R2 indicates no leakage\n",
    "    print(\"\\n No leakage detected! Chosen model is safe.\")\n",
    "elif shuffled_r2 < 0.2: # Very small R2 indicates likely no leakage\n",
    "    print(\"\\n Very small R2 â€” likely no leakage. Inspect if needed.\")\n",
    "else:  # Higher R2 indicates possible leakage\n",
    "    print(\"\\n Possible leakage â€” investigate feature engineering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89766444",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1124af",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE = MODELS_PATH / f\"best_regression_model.joblib\" # Output file path\n",
    "joblib.dump(best_model, OUTFILE, compress=3) # Save the best model\n",
    "\n",
    "print(\"Saved best model to:\", OUTFILE) # Confirm save location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a2377",
   "metadata": {},
   "source": [
    "## Define `schema_dict` from `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {}\n",
    "\n",
    "for col in X_train.columns:\n",
    "    col_min = float(X_train[col].min())\n",
    "    col_max = float(X_train[col].max())\n",
    "    col_median = float(X_train[col].median())\n",
    "\n",
    "    # Safety in case min == max (e.g. constant feature)\n",
    "    if col_min == col_max:\n",
    "        col_min = col_min - 1.0\n",
    "        col_max = col_max + 1.0\n",
    "\n",
    "    schema_dict[col] = {\n",
    "        \"min\": col_min,\n",
    "        \"max\": col_max,\n",
    "        \"default\": col_median,\n",
    "    }\n",
    "\n",
    "print(\"Feature schema built for\", len(schema_dict), \"features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db12dc5",
   "metadata": {},
   "source": [
    "## Save Metdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_PATH = MODELS_PATH / \"regression_metadata.json\" # Metadata file path\n",
    "metadata = {\n",
    "    \"best_model\": best_model.__class__.__name__,\n",
    "    \"best_params\": best_model.get_params(),\n",
    "    \"mae\": best_row[\"MAE\"],\n",
    "    \"rmse\": best_row[\"RMSE\"],\n",
    "    \"r2\": best_row[\"R2\"],\n",
    "    \"feature_schema\": schema_dict   # used for UI inputs\n",
    "} # Create metadata dictionary\n",
    "\n",
    "json.dump(metadata, open(METADATA_PATH, \"w\"), indent=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faea6ab",
   "metadata": {},
   "source": [
    "## Save feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = DATA_PATH / \"model_outputs\"\n",
    "FEATURES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "clean_cols = X_train.columns.astype(str)\n",
    "\n",
    "output_path = FEATURES_PATH / \"feature_importance.csv\"\n",
    "print(\"Saving to:\", output_path)\n",
    "\n",
    "if len(importances) == len(clean_cols):\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\": clean_cols.tolist(),\n",
    "        \"importance\": importances.tolist()\n",
    "    })\n",
    "else:\n",
    "    print(f\"âš  Mismatch: {len(importances)} importances for {len(clean_cols)} features.\")\n",
    "    used_idx = np.where(importances > 0)[0]\n",
    "\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\":clean_cols[used_idx].tolist(),\n",
    "        \"importance\": importances[used_idx].tolist()\n",
    "    })\n",
    "fi = fi.reset_index(drop=True)\n",
    "fi.to_csv(output_path, index=False)\n",
    "print(\"Saved feature importances successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebcaf6",
   "metadata": {},
   "source": [
    "## Save hyperparameter search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f058d",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df.to_csv(FEATURES_PATH / \"hyperparameter_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e16dc8",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- The multi-model benchmark reveals clear performance variation across algorithms.\n",
    "Linear Regression performed the weakest, indicating that the PM2.5â€“feature relationships are non-linear and not well captured by a simple linear model.\n",
    "- Tree-based models (Decision Tree, Random Forest, XGBoost) consistently outperform linear methods, confirming that non-linear interactionsâ€”especially lag features, rolling windows, and meteorological interactionsâ€”are crucial for forecasting accuracy.\n",
    "- Random Forest and XGBoost produced the lowest RMSE values across the test set, demonstrating stronger generalisation and robustness to noise.\n",
    "- AdaBoost showed moderate performance but exhibited higher variance in predictions, particularly during high-pollution events.\n",
    "- The hyperparameter search successfully improved each modelâ€™s performance relative to default settings, particularly by tuning depth, learning rate, and ensemble size.\n",
    "- Predicted vs Actual plots for the best model show tight alignment around the identity line, while residuals remain centred around zero with no major systematic structure, suggesting well-calibrated predictions.\n",
    "- Feature importance (where available) highlights the strong influence of lag features and rolling means, reinforcing evidence from H4â€“H5 that temporal dependency is a dominant predictive factor in PM2.5 dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120b773",
   "metadata": {},
   "source": [
    "\n",
    "## Justification\n",
    "\n",
    "- Evaluating multiple algorithms ensures the chosen model is not selected arbitrarily but based on systematic comparison with consistent metrics (MAE, RMSE, RÂ²) and identical training/testing splits.\n",
    "- Using TimeSeriesSplit respects temporal ordering, preventing data leakage and ensuring the validation process mirrors real-world forecasting workflows.\n",
    "- Hyperparameter optimisation via GridSearchCV improves fairness across models and extracts true performance potential, especially for ensemble methods that depend heavily on tuning.\n",
    "- The superior performance of tree-based models is theoretically consistent with the domain:\n",
    "PM2.5 behaviour is influenced by non-linear meteorological interactions, lag effects, and atmospheric stabilityâ€”all better captured by tree ensembles than linear models.\n",
    "- The residual and prediction diagnostics confirm the absence of major bias or structural errors, validating the reliability of the selected best model for downstream forecasting.\n",
    "- By saving the best estimator, Notebook 11 forms the foundation for Notebook 12, where the model is operationalised for short-term forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced88fe",
   "metadata": {},
   "source": [
    "## Summary â€“ hypothesis title goes here\n",
    "\n",
    "- Multiple ML algorithms were evaluated using systematic cross-validation\n",
    "- Performance was compared using RMSE, MAE, and RÂ²\n",
    "- A single best model was chosen based on test performance\n",
    "- The best model was saved for Notebook 12 â€“ Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ee638",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### AI Assistance Note\n",
    "\n",
    "Some narrative text and minor formatting or wording improvements in this notebook were supported by AI-assisted tools (ChatGPT for documentation clarity, Copilot for small routine code suggestions, and Grammarly for proofreading). All analysis, code logic, feature engineering, modelling, and interpretations were independently created by the author."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
